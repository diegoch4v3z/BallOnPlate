{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INTEL CORPORATION CONFIDENTIAL AND PROPRIETARY\n",
    "# \n",
    "# Copyright © 2020-2021 Intel Corporation.\n",
    "# \n",
    "# This software and the related documents are Intel copyrighted\n",
    "# materials, and your use of them is governed by the express \n",
    "# license under which they were provided to you (License). Unless\n",
    "# the License provides otherwise, you may not use, modify, copy, \n",
    "# publish, distribute, disclose or transmit  this software or the\n",
    "# related documents without Intel's prior written permission.\n",
    "# \n",
    "# This software and the related documents are provided as is, with\n",
    "# no express or implied warranties, other than those that are \n",
    "# expressly stated in the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate KNN search on Loihi\n",
    "This notebook and module show how to implement the approximate KNN search algorithm described in the paper below:\n",
    "\n",
    ">E. Paxon Frady, Garrick Orchard, David Florey, Nabil Imam, Ruokun Liu, Joyesh Mishra, Jonathan Tse, Andreas Wild, Friedrich T. Sommer, and Mike Davies. 2020. Neuromorphic Nearest Neighbor Search Using Intel's Pohoiki Springs. In Proceedings of the Neuro-inspired Computational Elements Workshop (NICE '20). Association for Computing Machinery, New York, NY, USA, Article 23, 1–10.  \n",
    "DOI: https://doi.org/10.1145/3381755.3398695  \n",
    "PrePrint: https://arxiv.org/abs/2004.12691   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nxsdk\n",
    "import time\n",
    "from nxsdk_modules.knn.src.dimensionReduction import DimensionReduction as DR\n",
    "from nxsdk_modules.knn.src.knn import Knn\n",
    "import numpy as np\n",
    "import os\n",
    "from nxsdk.logutils.nxlogging import set_verbosity, LoggingLevel\n",
    "set_verbosity(LoggingLevel.ERROR) #suppress all the compilation warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify a Loihi system to run on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Nahuku 32\n",
    "os.environ[\"PARTITION\"]= \"nahuku32\"\n",
    "os.environ[\"BOARD\"]= \"ncl-ext-ghrd-01\" # for external vLab\n",
    "#os.environ[\"BOARD\"]= \"ncl-ghrd-04\"     # for internal\n",
    "\n",
    "# For Pohoiki\n",
    "#os.environ[\"PARTITION\"]= \"pohoiki\"\n",
    "#os.environ[\"BOARD\"]= \"ncl-ext-ps-01-dct-01\" # for external vLab\n",
    "#os.environ[\"BOARD\"]= \"ncl-ps-01-dct-01\"     # for internal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Detect how many chips the chosen Loihi system contains. Later we will use this to truncate the dataset down to the largest size that can fit on the chosen Loihi system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 Nahuku(s) detected\n"
     ]
    }
   ],
   "source": [
    "numChips = !srun --partition={os.environ[\"PARTITION\"]} --nodelist={os.environ[\"BOARD\"]} {nxsdk.__path__[0]}/bin/nx --detect-chips\n",
    "numChips = int(numChips[len(numChips)-1])\n",
    "numNahukus = numChips//32\n",
    "print(\"{} Nahuku(s) detected\".format(numNahukus))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the dataset \n",
    "Specify the location of the dataset, query, and optional encoding file <br/>\n",
    "If the dataset folder doesn't exist, download the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasetFolder = \"{}/gist\".format(os.getcwd())\n",
    "encodingFile = '{}/encode_matrix.npy'.format(datasetFolder)\n",
    "datasetFile = '{}/gist_base.fvecs'.format(datasetFolder)\n",
    "queryFile = '{}/gist_query.fvecs'.format(datasetFolder)\n",
    "\n",
    "def readGistData(filename):\n",
    "    \"\"\"\n",
    "    Function for reading dataset format. Zero centers and normalizes each element\n",
    "    \"\"\"\n",
    "    data = np.fromfile(filename, dtype=np.float32)\n",
    "    data = data.reshape((data.shape[0]//961, -1))\n",
    "    assert (data.view(np.int32)[:,0] == 960).all(), \"unexpected file format\"\n",
    "\n",
    "    data = data[:,1:]\n",
    "    data -= np.expand_dims(data.mean(axis=1), axis=1)\n",
    "    data /= np.expand_dims(np.linalg.norm(data, axis=1), axis=1) + np.finfo(float).eps\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FTP is blocked on the external vlab, so you would need to download the dataset yourself and copy it over!\n",
    "Download the file on your own system:\n",
    "> wget ftp://ftp.irisa.fr/local/texmex/corpus/gist.tar.gz  \n",
    "\n",
    "Then copy to external vlab in the same folder as this notebook\n",
    "> scp gist.tar.gz (yourname)@(vlab):(thisfolder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(datasetFolder):\n",
    "    # If you are not on external vlab, you can uncomment the line below to directly download the dataset\n",
    "    #!wget ftp://ftp.irisa.fr/local/texmex/corpus/gist.tar.gz \n",
    "    \n",
    "    if not os.path.isfile(\"{}/gist.tar.gz\".format(datasetFolder)):\n",
    "        print(\"Error, the dataset file is missing. See instructions above\")\n",
    "        \n",
    "    !tar -zxvf gist.tar.gz && rm gist.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup KNN parameters\n",
    "| Parameter       | Description                                                                      | Comment\n",
    "|-----------------|----------------------------------------------------------------------------------|--------------\n",
    "| K               | The number of approximate nearest neighbours to return                           |\n",
    "| queryDuration   | Number of Loihi timesteps over which to encoded query as spikes                  | Controls temporal resolution\n",
    "| spikesPerQuery  | Number of spikes used to encode a query                                          | Each subsequent spike encodes the next largest dimension\n",
    "| neuronThreshold | The sensitivity of the neurons                                                   | \n",
    "| benchmark       | Tells the lakemonts whether to gather and return per-timestep timing information | Useful for debug, but communicating the output slows things down"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 100\n",
    "queryDuration = 120\n",
    "spikesPerQuery = 240\n",
    "neuronThreshold = 64000\n",
    "benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup dimensionality reduction\n",
    "We use a projection matrix to reduce the dimensionality of the dataset.  \n",
    "If the projection matrix has already been saved as a file (encodingFile) it will be loaded, otherwise it will be created from the dataset (can take a while)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnDataset = readGistData(datasetFile)\n",
    "dr = DR(encodingFile=encodingFile, dataset=knnDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the dataset\n",
    "We can fit 2400 dataset samples per chip.  \n",
    "The code below reduces the number of samples in the dataset to the size we can fit on the system, and applies dimensionality reduction.  \n",
    "\"systemNum\" can be used to split the dataset across multiple systems. The n-th system would be run by setting systemNum=n. For example, running on Pohoiki columns 0/1/2 would be achieved by setting systemNum = 0/1/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "systemNum = 0\n",
    "datasetSize = 2400*numChips\n",
    "knnDataset = knnDataset[np.arange(systemNum*datasetSize, (systemNum+1)*datasetSize), :]\n",
    "reducedDataset = dr.reduce(knnDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup the KNN module\n",
    "This sets up the board object and starts it running. This takes about 5 mins for Nahuku, and multiples of 5 mins for multiple Nahukus (Pohoiki)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Encoding probes... sters... \r"
     ]
    }
   ],
   "source": [
    "knn = Knn(reducedDataset, neuronThreshold, k, queryDuration, spikesPerQuery, benchmark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the queries and query the KNN module\n",
    "Although queries are passed as an ndarray, the test function processes them as if they were arriving one at a time. The steps run by \"test()\" for each query are:\n",
    "* Dimensionality reduction\n",
    "* Encoding as spikes\n",
    "* Sending to the Host\n",
    "* Running on the Loihi system\n",
    "* Receiving the results from the Host\n",
    "* Tie breaking on the superhost (if there is a multiway tie for K'th place)\n",
    "\n",
    "The returned parameters are:\n",
    "* results: An array of results with \"n\" rows and \"K\" columns\n",
    "* queryEndTime: The time at which the K'th solution was found on Loihi for each query (An array of \"n\" times. The difference between elements gives the query duration)\n",
    "* numSteps: The number of Loihi timesteps before the K'th solution was found for each query (Array of \"n\" timestep measurements). Only populate if benchmark==True.  \n",
    "* timePerTimestep: A list of \"n\" arrays, with each array containing timestep durations measured in microseconds. Calculated by measuring the time at the beginning of each spiking phase and taking the differences. The first array element is the time since the start of the last timestep of the previous sample and therefore includes system reset and communication of result back to the host. This variable is only populated if benchmark==True\n",
    "\n",
    "Programming the system takes approximately 1 minute per Nahuku board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Transferring spikes... . \r"
     ]
    }
   ],
   "source": [
    "queries = readGistData(queryFile)\n",
    "numQueryIndices = queries.shape[0]\n",
    "results, queryEndTime, numSteps, timePerTimestep =  knn.test(queries, knnDataset, encodingFunction=dr.reduce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The call below tells the module we are done and that it can disconnect from the Loihi system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Processing timeseries... \r"
     ]
    }
   ],
   "source": [
    "knn.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute ground truth and accuracy\n",
    "For each query, find the closest K dataset samples using the cosine similarity distance.  \n",
    "For each query, compute what percentage of the top K dataset samples were found by Loihi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "groundTruth = knn.computeGroundTruth(knnDataset, queries, k)\n",
    "accuracy = np.array([np.intersect1d(groundTruth[ii], res, assume_unique=True, return_indices=False).shape[0] for ii,res in enumerate(results)])/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print some statistics\n",
    "The embedded x86 cores on Loihi record the time at which the k'th solution was found for each query (queryEndTime).  \n",
    "Loihi time per query is calculated by taking the difference of these times. i.e. it is measured as the time between finding the k'th solution for subsequent queries, including time required to receive a query, return the result, and reset the Loihi system in between queries.  \n",
    "The knn module on the superhost first sends (n=\"knn.pipelining\") queries to the host without receiving any results.  \n",
    "Thereafter, the knn module must receive a result from the host to make space in the channel buffer before it can send another query.  \n",
    "In the inital phase (first \"knn.pipelining\" queries) the Loihi system runs quickly, but thereafter the speed is limited by the superhost.\n",
    "\n",
    "The other time measurements for the superhost are:\n",
    "\n",
    "\n",
    "| Description         | Includes                       |\n",
    "|---------------------|--------------------------------|\n",
    "|Pre-processing       | Dimensionality reduction, normalization, sorting to find the strongest components, converting to spikes, encoding spikes as a lakemont message |\n",
    "|Send a query         | Communicating the lakemont message from superhost to host (network latency) |\n",
    "|Receive a result     | Receiving a message containing results from the host (network latency) |\n",
    "|Post-process result  | Interpreting the Lakemont message and computing ground truth distance for any tied results                               |\n",
    "|Receive timing info  | Receiving precise timing information (timePerTimestep) from the host (network latency)            |\n",
    "|Post-process timing  | Interpreting the timing message                               |\n",
    "\n",
    "The bottleneck is network latency in the superhost to host communication.  \n",
    "Pre- and Post-processing times are heavily affected by the current machine load from other users.\n",
    "\n",
    "\"numSteps\" and \"timePerTimestep\" are only populated if benchmark==True.   \n",
    "numSteps is an array with length equal to the number of queries, indicating how many Loihi timesteps each query took.  \n",
    "timePerTimestep is a list of arrays, one array per query, where each array element indicates the difference in time between the start of the current timestep and previous timestep. The n-th array will have length numSteps[n]. The first element in each array is the time since the beginning of the last timestep of the previous query and includes all the time taken to communicate results to the host, receive a new query, and reset the system back to its initial state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN results for params:\n",
      "k\t\t100\n",
      "queryDuration\t120\n",
      "spikesPerQuery\t240\n",
      "neuronThreshold\t64000\n",
      "datasetSize\t76800\n",
      "\n",
      "Accuracy: \t\t mean 87.60%\t min 1.00%\t max 100.00%\n",
      "Loihi time per query:\t mean 9.92ms\t min 1.63ms\t max 65.59ms\n",
      "(first 64 queries:\t mean 2.14ms\t min 1.63ms\t max 9.69ms)\n",
      "\n",
      "Average pre-processing time per query:\t\t0.34ms\n",
      "Average time to send a query to the host: \t1.87ms\n",
      "Average time to receive a result from the host:\t3.92ms\n",
      "Average post-processing time on the superhost \t0.63ms\n",
      "\n",
      "Additional Timing info:\n",
      "Timesteps per query:\t mean 135.50\t min 110.00\t max 170.00\n",
      "Receiving per timestep timing information averaged \t\t3.53ms per query\n",
      "Post-processing per timestep timing information averaged \t0.00ms per query\n"
     ]
    }
   ],
   "source": [
    "timePerSample = np.diff(queryEndTime)\n",
    "print(\"KNN results for params:\\nk\\t\\t{}\\nqueryDuration\\t{}\\nspikesPerQuery\\t{}\\nneuronThreshold\\t{}\\ndatasetSize\\t{}\".format(k, \n",
    "                                                                                                                          queryDuration, \n",
    "                                                                                                                          spikesPerQuery, \n",
    "                                                                                                                          neuronThreshold,\n",
    "                                                                                                                          datasetSize))\n",
    "print(\"\\nAccuracy: \\t\\t mean {:.2f}%\\t min {:.2f}%\\t max {:.2f}%\".format(np.mean(accuracy)*100, \n",
    "                                                                              np.min(accuracy)*100, \n",
    "                                                                              np.max(accuracy)*100))\n",
    "print(\"Loihi time per query:\\t mean {:.2f}ms\\t min {:.2f}ms\\t max {:.2f}ms\".format(np.mean(timePerSample)*1000, \n",
    "                                                                                   np.min(timePerSample)*1000, \n",
    "                                                                                   np.max(timePerSample)*1000))\n",
    "print(\"(first {} queries:\\t mean {:.2f}ms\\t min {:.2f}ms\\t max {:.2f}ms)\".format(knn.pipelining, \n",
    "                                                                                 np.mean(timePerSample[:knn.pipelining])*1000, \n",
    "                                                                                 np.min(timePerSample[:knn.pipelining])*1000, \n",
    "                                                                                 np.max(timePerSample[:knn.pipelining])*1000))\n",
    "\n",
    "print(\"\\nAverage pre-processing time per query:\\t\\t{:.2f}ms\".format(1000*knn.queryPreProcTime/numQueryIndices))\n",
    "print(\"Average time to send a query to the host: \\t{:.2f}ms\".format(1000*knn.querySendTime/numQueryIndices))\n",
    "print(\"Average time to receive a result from the host:\\t{:.2f}ms\".format(1000*knn.resultRecTime/numQueryIndices))\n",
    "print(\"Average post-processing time on the superhost \\t{:.2f}ms\".format(1000*knn.resultProcTime/numQueryIndices))\n",
    "\n",
    "if benchmark:\n",
    "    print(\"\\nAdditional Timing info:\")\n",
    "    print(\"Timesteps per query:\\t mean {:.2f}\\t min {:.2f}\\t max {:.2f}\".format(np.mean(numSteps), \n",
    "                                                                                np.min(numSteps), \n",
    "                                                                                np.max(numSteps)))\n",
    "\n",
    "    print(\"Receiving per timestep timing information averaged \\t\\t{:.2f}ms per query\".format(1000*knn.timingRecTime/numQueryIndices))\n",
    "    print(\"Post-processing per timestep timing information averaged \\t{:.2f}ms per query\".format(knn.timingProcTime/numQueryIndices))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
